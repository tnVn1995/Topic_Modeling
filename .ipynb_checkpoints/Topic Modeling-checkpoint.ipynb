{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modeling with Latent Dirichlet Allocation(LDA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T18:07:27.875190Z",
     "start_time": "2020-04-11T18:07:23.729604Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Data processing\n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "#Visualization\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T00:36:50.385201Z",
     "start_time": "2020-04-11T00:36:50.380215Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T00:45:48.319946Z",
     "start_time": "2020-04-11T00:45:48.087998Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of articles is: 1740\n"
     ]
    }
   ],
   "source": [
    "data_path = Path('./data/nipstxt/')\n",
    "folders = list(data_path.glob('*nips*'))\n",
    "papers = []\n",
    "for folder in folders:\n",
    "    for file in list(folder.glob('*')):\n",
    "        with open(file, encoding='utf-8', errors='ignore', mode='r+') as f:\n",
    "            data = f.read()\n",
    "        papers.append(data)\n",
    "print(f'The number of articles is: {len(papers)}')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's peek into the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T00:48:25.977367Z",
     "start_time": "2020-04-11T00:48:25.972392Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \n",
      "CONNECTIVITY VERSUS ENTROPY \n",
      "Yaser S. Abu-Mostafa \n",
      "California Institute of Technology \n",
      "Pasadena, CA 91125 \n",
      "ABSTRACT \n",
      "How does the connectivity of a neural network (number of synapses per \n",
      "neuron) relate to the complexity of the problems it can handle (measured by \n",
      "the entropy)? Switching theory would suggest no relation at all, since all Boolean \n",
      "functions can be implemented using a circuit with very low connectivity (e.g., \n",
      "using two-input NAND gates). However, for a network that learns a problem \n",
      "from examples using a local learning rule, we prove that the entropy of the \n",
      "problem becomes a lower bound for the connectivity of the network. \n",
      "INTRODUCTION \n",
      "The most distinguishing feature of neural networks is their ability to spon- \n",
      "taneously learn the desired function from 'training' samples, i.e., their ability \n",
      "to program themselves. Clearly, a given neural network cannot just learn any \n",
      "function, there must be some restrictions on which networks can learn which \n",
      "functions. One obv\n"
     ]
    }
   ],
   "source": [
    "print(papers[0][:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T00:52:02.756898Z",
     "start_time": "2020-04-11T00:51:39.523082Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "wtk = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "wnl = nltk.stem.wordnet.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T01:10:25.576940Z",
     "start_time": "2020-04-11T01:09:46.083288Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def normalize_corpus(papers):\n",
    "    \"\"\"Tokenize, lemmatize, remove stopwords and terms with less than 1 character\"\"\"\n",
    "    norm_papers = []\n",
    "    for paper in papers:\n",
    "        paper = paper.lower()\n",
    "        paper_tokens = [token.strip() for token in wtk.tokenize(paper)]\n",
    "        paper_tokens = [wnl.lemmatize(token) for token in paper_tokens if not token.isnumeric()]\n",
    "        paper_tokens = [token for token in paper_tokens if len(token) > 1]\n",
    "        paper_tokens = [token for token in paper_tokens if token not in stop_words]\n",
    "        paper_tokens = list(filter(None, paper_tokens))\n",
    "        if paper_tokens:\n",
    "            norm_papers.append(paper_tokens)\n",
    "    return norm_papers\n",
    "\n",
    "norm_papers = normalize_corpus(papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T01:13:32.060951Z",
     "start_time": "2020-04-11T01:13:32.055965Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample tokenized texts:\n",
      " ['connectivity', 'versus', 'entropy', 'yaser', 'abu', 'mostafa', 'california', 'institute', 'technology', 'pasadena', 'ca', 'abstract', 'doe', 'connectivity', 'neural', 'network', 'number', 'synapsis', 'per', 'neuron']\n"
     ]
    }
   ],
   "source": [
    "print(f'Sample tokenized texts:\\n {norm_papers[0][0:20]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Generating bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T01:23:04.465168Z",
     "start_time": "2020-04-11T01:22:41.670422Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['connectivity', 'versus', 'entropy', 'yaser', 'abu_mostafa', 'california_institute', 'technology_pasadena', 'ca_abstract', 'doe', 'connectivity', 'neural_network', 'number', 'synapsis', 'per', 'neuron', 'relate', 'complexity', 'problem', 'handle', 'measured', 'entropy', 'switching', 'theory', 'would', 'suggest', 'relation', 'since', 'boolean_function', 'implemented', 'using', 'circuit', 'low', 'connectivity', 'using', 'two', 'input', 'nand', 'gate', 'however', 'network', 'learns', 'problem', 'example', 'using', 'local', 'learning_rule', 'prove', 'entropy', 'problem', 'becomes']\n"
     ]
    }
   ],
   "source": [
    "# ignore words and bigrams with total count less than 20 accross the text corpus\n",
    "bigram = gensim.models.Phrases(norm_papers, min_count=20, delimiter=b'_')\n",
    "bigram_model = gensim.models.phrases.Phraser(bigram)\n",
    "# \n",
    "normalize_corpus_bigram = [bigram_model[doc] for doc in norm_papers]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The bigrams generated from gensim model are two-word phrases. For example, california_institute, technology_pasadena are two bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T07:34:04.954865Z",
     "start_time": "2020-04-11T07:34:04.947885Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text corpus after generating bigrams:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['connectivity',\n",
       " 'versus',\n",
       " 'entropy',\n",
       " 'yaser',\n",
       " 'abu_mostafa',\n",
       " 'california_institute',\n",
       " 'technology_pasadena',\n",
       " 'ca_abstract',\n",
       " 'doe',\n",
       " 'connectivity']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Sample text corpus after generating bigrams:')\n",
    "normalize_corpus_bigram[0][0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since the model doesn't understand words, we'll vectorize our text corpus to feed in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T07:35:47.076451Z",
     "start_time": "2020-04-11T07:35:43.557890Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample word to number mappings: [(0, '0a'), (1, '2h'), (2, '2h2'), (3, '2he'), (4, '2n'), (5, '__c'), (6, '_c'), (7, '_k'), (8, 'a2'), (9, 'ability'), (10, 'abu_mostafa'), (11, 'access'), (12, 'accommodate'), (13, 'according'), (14, 'accumulated')]\n",
      "Total Vocabulary Size: 79687\n"
     ]
    }
   ],
   "source": [
    "dictionary = gensim.corpora.Dictionary(normalize_corpus_bigram)\n",
    "print('Sample word to number mappings:', list(dictionary.items())[:15])\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now each word is represented by an integer. We have 79687 unique words in our corpus, which corresponds to 79687 unique integers. However, many words in this corpus are not useful in our topic modeling task - we are trying to differentiate topics within our corpus. If words appear too frequent or too infrequent, they will not contribute much to differentiating different topics as they are either too general or too specific. So we'll remove these words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T07:46:53.131868Z",
     "start_time": "2020-04-11T07:46:52.928302Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Vocabulary Size: 8240\n"
     ]
    }
   ],
   "source": [
    "# Filter out words that appear in less than 20 documents \n",
    "# and more than 60% of the documents in our corpus\n",
    "dictionary.filter_extremes(no_below=20, no_above=0.6)\n",
    "print('Total Vocabulary Size:', len(dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T07:49:25.337899Z",
     "start_time": "2020-04-11T07:49:23.436293Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(12, 3), (14, 1), (15, 1), (16, 1), (17, 13), (20, 1), (24, 1), (26, 1), (31, 3), (35, 1), (36, 1), (40, 3), (41, 5), (48, 1), (53, 1), (55, 1), (56, 2), (58, 1), (60, 3), (63, 5), (64, 4), (65, 2), (73, 1), (74, 1), (75, 1), (76, 1), (77, 3), (82, 1), (83, 4), (84, 1), (85, 1), (86, 2), (90, 2), (97, 2), (98, 3), (107, 1), (111, 1), (121, 2), (122, 4), (123, 2), (126, 2), (129, 1), (133, 1), (134, 1), (136, 6), (137, 1), (145, 1), (147, 1), (149, 1), (153, 5)]\n"
     ]
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(text) for text in normalize_corpus_bigram]\n",
    "print(bow_corpus[1][:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T07:50:14.318498Z",
     "start_time": "2020-04-11T07:50:14.256811Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('aip', 3), ('although', 1), ('american_institute', 1), ('amount', 1), ('analog', 13), ('appears', 1), ('architecture', 1), ('aspect', 1), ('available', 3), ('become', 1), ('becomes', 1), ('binary', 3), ('biological', 5), ('cannot', 1), ('circuit', 1), ('collective', 1), ('compare', 2), ('complex', 1), ('computing', 3), ('conference', 5), ('connected', 4), ('connectivity', 2), ('define', 1), ('defined', 1), ('defines', 1), ('definition', 1), ('denker', 3), ('designed', 1), ('desired', 4), ('diagonal', 1), ('difference', 1), ('directly', 2), ('doe', 2), ('el', 2), ('element', 3), ('equivalent', 1), ('eventually', 1), ('feature', 2), ('final', 4), ('find', 2), ('fixed', 2), ('furthermore', 1), ('generating', 1), ('get', 1), ('global', 6), ('go', 1), ('hence', 1), ('hold', 1), ('idea', 1), ('implemented', 5)]\n"
     ]
    }
   ],
   "source": [
    "# Words and their frequencies, respectively\n",
    "print([(dictionary[idx] , freq) for idx, freq in bow_corpus[1][:50]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA for Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T08:04:35.167545Z",
     "start_time": "2020-04-11T08:01:37.266891Z"
    }
   },
   "source": [
    "For LDA, the number of topics in the text corpus is a hyperparameter to tune. We'll tune our model for topics from 2 to 40 to see which number of topics will best represent our text corpus. We'll use coherence value (cv) as our evaluating parameters. The higher the cv, the better the model in differentiating topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-11T18:34:42.387010Z",
     "start_time": "2020-04-11T18:08:21.646657Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Inputs:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Outputs:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    perplexity_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        # Creating a model for num_topics\n",
    "        model = gensim.models.LdaModel(corpus=bow_corpus, id2word=dictionary, chunksize=1740,\n",
    "                                   alpha=\"auto\", eta=\"auto\", random_state=42, \n",
    "                                   iterations=500, num_topics=num_topics, passes=20, \n",
    "                                   eval_every=None)\n",
    "        model_list.append(model)\n",
    "        # Computing coherence score\n",
    "        coherencemodel = gensim.models.CoherenceModel(model=model, \n",
    "                                        texts=texts, \n",
    "                                        dictionary=dictionary, \n",
    "                                        coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "        perplexity_values.append(model.log_perplexity(corpus))\n",
    "    return model_list, coherence_values, perplexity_values\n",
    "\n",
    "# Training models\n",
    "model_list, coherence_values, perplexity_values = compute_coherence_values(\n",
    "                                                        dictionary=dictionary, \n",
    "                                                        corpus=bow_corpus, \n",
    "                                                        texts=normalize_corpus_bigram, \n",
    "                                                        start=2, limit=40, \n",
    "                                                        step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T03:19:58.075382Z",
     "start_time": "2020-04-12T03:19:57.407772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluating models' performance\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.title('Model Performance')\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest coherence value is around 15. I'll pick this number of topics to differentiate our text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T01:35:52.827339Z",
     "start_time": "2020-04-12T01:35:52.822371Z"
    }
   },
   "outputs": [],
   "source": [
    "optimal_model = model_list[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the dominant topic in each sentence\n",
    "\n",
    "Firstly, we'll take a look at the distribution of topics in our text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T03:51:45.834139Z",
     "start_time": "2020-04-12T03:51:45.804187Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Num_Documents</th>\n",
       "      <th>Perc_Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>circuit, chip, neuron, voltage, current, analo...</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.1443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>node, bound, let, theorem, class, size, probab...</td>\n",
       "      <td>203.0</td>\n",
       "      <td>0.1167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>neuron, state, pattern, dynamic, equation, mem...</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>neuron, state, pattern, dynamic, equation, mem...</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>circuit, chip, neuron, voltage, current, analo...</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>neuron, cell, spike, response, firing, activit...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.0730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>neuron, cell, spike, response, firing, activit...</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.0649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>node, bound, let, theorem, class, size, probab...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.0644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>image, visual, motion, object, cell, response,...</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.0592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>node, bound, let, theorem, class, size, probab...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>13.0</td>\n",
       "      <td>neuron, cell, spike, response, firing, activit...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>unit, pattern, layer, representation, activity...</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.0529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>circuit, chip, neuron, voltage, current, analo...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>node, bound, let, theorem, class, size, probab...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Dominant_Topic                                     Topic_Keywords  \\\n",
       "1.0              6.0  circuit, chip, neuron, voltage, current, analo...   \n",
       "4.0             11.0  node, bound, let, theorem, class, size, probab...   \n",
       "2.0              5.0  neuron, state, pattern, dynamic, equation, mem...   \n",
       "3.0              5.0  neuron, state, pattern, dynamic, equation, mem...   \n",
       "10.0             6.0  circuit, chip, neuron, voltage, current, analo...   \n",
       "9.0             13.0  neuron, cell, spike, response, firing, activit...   \n",
       "11.0            13.0  neuron, cell, spike, response, firing, activit...   \n",
       "13.0            11.0  node, bound, let, theorem, class, size, probab...   \n",
       "6.0              2.0  image, visual, motion, object, cell, response,...   \n",
       "5.0             11.0  node, bound, let, theorem, class, size, probab...   \n",
       "8.0             13.0  neuron, cell, spike, response, firing, activit...   \n",
       "7.0              7.0  unit, pattern, layer, representation, activity...   \n",
       "12.0             6.0  circuit, chip, neuron, voltage, current, analo...   \n",
       "0.0             11.0  node, bound, let, theorem, class, size, probab...   \n",
       "\n",
       "      Num_Documents  Perc_Documents  \n",
       "1.0           251.0          0.1443  \n",
       "4.0           203.0          0.1167  \n",
       "2.0           180.0          0.1034  \n",
       "3.0           132.0          0.0759  \n",
       "10.0          131.0          0.0753  \n",
       "9.0           127.0          0.0730  \n",
       "11.0          113.0          0.0649  \n",
       "13.0          112.0          0.0644  \n",
       "6.0           103.0          0.0592  \n",
       "5.0           101.0          0.0580  \n",
       "8.0           101.0          0.0580  \n",
       "7.0            92.0          0.0529  \n",
       "12.0           56.0          0.0322  \n",
       "0.0            38.0          0.0218  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics = df_dominant_topics.head(14)\n",
    "\n",
    "df_dominant_topics.sort_values(['Num_Documents'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 6 dominates most frequently in our corpus with 251 appearances. The least frequently dominant is topic 0 with 38 appearances. If we wish to understand what each topic is. The easiest way is to look at the most dominant topic of a document and its texts. We'll find the most dominant topic in each document based on the percentage contribution in that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T01:59:56.064658Z",
     "start_time": "2020-04-12T01:59:56.056679Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=bow_corpus, texts=normalize_corpus_bigram):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T02:00:53.527201Z",
     "start_time": "2020-04-12T02:00:36.687390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5136</td>\n",
       "      <td>node, bound, let, theorem, class, size, probab...</td>\n",
       "      <td>[connectivity, versus, entropy, yaser, abu_mos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>circuit, chip, neuron, voltage, current, analo...</td>\n",
       "      <td>[stochastic, learning, network, electronic, im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.4953</td>\n",
       "      <td>neuron, state, pattern, dynamic, equation, mem...</td>\n",
       "      <td>[learning, general, network, amir, atiya, depa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>neuron, state, pattern, dynamic, equation, mem...</td>\n",
       "      <td>[artificial_neural, network, spatio_temporal, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5750</td>\n",
       "      <td>node, bound, let, theorem, class, size, probab...</td>\n",
       "      <td>[property, network, neuron, like, element, pie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.2912</td>\n",
       "      <td>node, bound, let, theorem, class, size, probab...</td>\n",
       "      <td>[supervised_learning, probability_distribution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.7914</td>\n",
       "      <td>image, visual, motion, object, cell, response,...</td>\n",
       "      <td>[centric, model, orientation, map, primary_vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.3334</td>\n",
       "      <td>unit, pattern, layer, representation, activity...</td>\n",
       "      <td>[analysis, comparison, different, learning, al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>neuron, cell, spike, response, firing, activit...</td>\n",
       "      <td>[simulation, suggest, information_processing, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.4007</td>\n",
       "      <td>neuron, cell, spike, response, firing, activit...</td>\n",
       "      <td>[optimal, neural, spike, classification, amir,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0            0            11.0              0.5136   \n",
       "1            1             6.0              0.5302   \n",
       "2            2             5.0              0.4953   \n",
       "3            3             5.0              0.3548   \n",
       "4            4            11.0              0.5750   \n",
       "5            5            11.0              0.2912   \n",
       "6            6             2.0              0.7914   \n",
       "7            7             7.0              0.3334   \n",
       "8            8            13.0              0.9997   \n",
       "9            9            13.0              0.4007   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  node, bound, let, theorem, class, size, probab...   \n",
       "1  circuit, chip, neuron, voltage, current, analo...   \n",
       "2  neuron, state, pattern, dynamic, equation, mem...   \n",
       "3  neuron, state, pattern, dynamic, equation, mem...   \n",
       "4  node, bound, let, theorem, class, size, probab...   \n",
       "5  node, bound, let, theorem, class, size, probab...   \n",
       "6  image, visual, motion, object, cell, response,...   \n",
       "7  unit, pattern, layer, representation, activity...   \n",
       "8  neuron, cell, spike, response, firing, activit...   \n",
       "9  neuron, cell, spike, response, firing, activit...   \n",
       "\n",
       "                                                Text  \n",
       "0  [connectivity, versus, entropy, yaser, abu_mos...  \n",
       "1  [stochastic, learning, network, electronic, im...  \n",
       "2  [learning, general, network, amir, atiya, depa...  \n",
       "3  [artificial_neural, network, spatio_temporal, ...  \n",
       "4  [property, network, neuron, like, element, pie...  \n",
       "5  [supervised_learning, probability_distribution...  \n",
       "6  [centric, model, orientation, map, primary_vis...  \n",
       "7  [analysis, comparison, different, learning, al...  \n",
       "8  [simulation, suggest, information_processing, ...  \n",
       "9  [optimal, neural, spike, classification, amir,...  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get most dominant topic\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=bow_corpus, texts=normalize_corpus_bigram)\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe shows us the dominant topic in each document (represented by the Text column). It also shows us the dominant keywords for each topic. Based on the keywords and their respective text we could understand certain topics. Let's see how we can interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T03:51:21.803317Z",
     "start_time": "2020-04-12T03:51:21.799357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords for topic 11: node, bound, let, theorem, class, size, probability, threshold, proof, complexity\n"
     ]
    }
   ],
   "source": [
    "print(f'Keywords for topic 11: {df_dominant_topic[\"Keywords\"][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic 11 mentions node, bound, theorem, proof, etc. It looks like this is a theoretical paper that is trying to prove or obtain an optimal bound for something. We can peek further by looking at the respective document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T03:51:24.778891Z",
     "start_time": "2020-04-12T03:51:24.773693Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 50 words for topic 11: ['connectivity', 'versus', 'entropy', 'yaser', 'abu_mostafa', 'california_institute', 'technology_pasadena', 'ca_abstract', 'doe', 'connectivity', 'neural_network', 'number', 'synapsis', 'per', 'neuron', 'relate', 'complexity', 'problem', 'handle', 'measured', 'entropy', 'switching', 'theory', 'would', 'suggest', 'relation', 'since', 'boolean_function', 'implemented', 'using', 'circuit', 'low', 'connectivity', 'using', 'two', 'input', 'nand', 'gate', 'however', 'network', 'learns', 'problem', 'example', 'using', 'local', 'learning_rule', 'prove', 'entropy', 'problem', 'becomes']\n"
     ]
    }
   ],
   "source": [
    "print(f'First 50 words for topic 11: {df_dominant_topic[\"Text\"][0][0:50]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this document is about solving a problem about the relationship of neurons in a neural network to achieve global optimum. As shown in the dataframe above, each document can contain many topics. Document 0 has topic 11 as the most dominant. However, topic 11 only contributes ~50% to the total topics of document 0. We can try to understand each topic by finding the document where they contribute most out of all documents in the text corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T02:38:55.627786Z",
     "start_time": "2020-04-12T02:38:55.569930Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8865</td>\n",
       "      <td>kernel, character, constraint, solution, suppo...</td>\n",
       "      <td>[geometric, interpretation, svm, classifier, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>distribution, variable, approximation, prior, ...</td>\n",
       "      <td>[nonlinear, markov, network, continuous_variab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>image, visual, motion, object, cell, response,...</td>\n",
       "      <td>[neural, dynamic, motion, segmentation, groupi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>control, dynamic, equation, vector, trajectory...</td>\n",
       "      <td>[integrated, architecture, adaptive, neural_ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>unit, training, word, state, sequence, rule, t...</td>\n",
       "      <td>[recurrent_cascade, correlation, architecture,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9613</td>\n",
       "      <td>neuron, state, pattern, dynamic, equation, mem...</td>\n",
       "      <td>[dynamic, analog, neural_network, time_delay, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>circuit, chip, neuron, voltage, current, analo...</td>\n",
       "      <td>[satyanarayana, tsividis, graf, reconfigurable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>unit, pattern, layer, representation, activity...</td>\n",
       "      <td>[topography, ocular_dominance, positive, corre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>training, estimate, prediction, distribution, ...</td>\n",
       "      <td>[bias_variance, combination, least_square, est...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>image, classifier, class, feature, classificat...</td>\n",
       "      <td>[boundary, hunting, radial_basis, function, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>state, action, policy, control, reinforcement_...</td>\n",
       "      <td>[finding, structure, reinforcement_learning, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>node, bound, let, theorem, class, size, probab...</td>\n",
       "      <td>[power, approximating, comparison, activation_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.8939</td>\n",
       "      <td>noise, code, vector, signal, filter, linear, m...</td>\n",
       "      <td>[regular, irregular, gallager, type, error_cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>neuron, cell, spike, response, firing, activit...</td>\n",
       "      <td>[simulation, suggest, information_processing, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic_Num  Topic_Perc_Contrib  \\\n",
       "0         0.0              0.8865   \n",
       "1         1.0              0.9996   \n",
       "2         2.0              0.9996   \n",
       "3         3.0              0.9996   \n",
       "4         4.0              0.9996   \n",
       "5         5.0              0.9613   \n",
       "6         6.0              0.9996   \n",
       "7         7.0              0.9995   \n",
       "8         8.0              0.9996   \n",
       "9         9.0              0.9995   \n",
       "10       10.0              0.9997   \n",
       "11       11.0              0.9996   \n",
       "12       12.0              0.8939   \n",
       "13       13.0              0.9997   \n",
       "\n",
       "                                             Keywords  \\\n",
       "0   kernel, character, constraint, solution, suppo...   \n",
       "1   distribution, variable, approximation, prior, ...   \n",
       "2   image, visual, motion, object, cell, response,...   \n",
       "3   control, dynamic, equation, vector, trajectory...   \n",
       "4   unit, training, word, state, sequence, rule, t...   \n",
       "5   neuron, state, pattern, dynamic, equation, mem...   \n",
       "6   circuit, chip, neuron, voltage, current, analo...   \n",
       "7   unit, pattern, layer, representation, activity...   \n",
       "8   training, estimate, prediction, distribution, ...   \n",
       "9   image, classifier, class, feature, classificat...   \n",
       "10  state, action, policy, control, reinforcement_...   \n",
       "11  node, bound, let, theorem, class, size, probab...   \n",
       "12  noise, code, vector, signal, filter, linear, m...   \n",
       "13  neuron, cell, spike, response, firing, activit...   \n",
       "\n",
       "                                                 Text  \n",
       "0   [geometric, interpretation, svm, classifier, d...  \n",
       "1   [nonlinear, markov, network, continuous_variab...  \n",
       "2   [neural, dynamic, motion, segmentation, groupi...  \n",
       "3   [integrated, architecture, adaptive, neural_ne...  \n",
       "4   [recurrent_cascade, correlation, architecture,...  \n",
       "5   [dynamic, analog, neural_network, time_delay, ...  \n",
       "6   [satyanarayana, tsividis, graf, reconfigurable...  \n",
       "7   [topography, ocular_dominance, positive, corre...  \n",
       "8   [bias_variance, combination, least_square, est...  \n",
       "9   [boundary, hunting, radial_basis, function, cl...  \n",
       "10  [finding, structure, reinforcement_learning, s...  \n",
       "11  [power, approximating, comparison, activation_...  \n",
       "12  [regular, irregular, gallager, type, error_cor...  \n",
       "13  [simulation, suggest, information_processing, ...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_topics_sorteddf_gensim = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_gensim = pd.concat([sent_topics_sorteddf_gensim, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "    \n",
    "sent_topics_sorteddf_gensim.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_gensim.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_gensim    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's peek into topic 11 one again. This time it contriutes to 99% of the respective document. Let's see what this document is about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-12T03:46:54.191198Z",
     "start_time": "2020-04-12T03:46:54.185948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First sampled texts in the document ['error_correcting', 'code', 'investigated', 'via', 'method', 'statistical_physic', 'transmitted', 'codeword', 'comprises', 'product', 'original', 'sage', 'bit', 'selected', 'two', 'randomly', 'constructed', 'sparse', 'matrix', 'number', 'non_zero', 'row_column', 'element', 'matrix', 'constitutes', 'family', 'code', 'show', 'shannon', 'channel', 'capacity', 'may', 'saturated', 'equilibrium', 'many', 'regular', 'code', 'slightly', 'lower', 'performance', 'obtained', 'others', 'may', 'higher', 'practical', 'relevance', 'decoding', 'aspect', 'con_sidered', 'employing', 'tap', 'approach', 'identical', 'commonly_used', 'belief_propagation', 'based', 'decoding', 'show', 'irregular', 'code', 'may', 'saturate', 'shannon', 'capacity', 'improved', 'dynamical', 'property', 'introduction', 'ever', 'increasing']\n"
     ]
    }
   ],
   "source": [
    "print(f'First sampled texts in the document {sent_topics_sorteddf_gensim[\"Text\"][12][30:100]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This topic is also about finding global optimum. Nevertheless, it differs from the previous article because this article is comparing some methods through experimenting. While as we talked about, the previous article adopts a proof-based approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we perform topic modeling on the NIPS conferences papers by using LDA from gensim. We look at how to tune in the number of topics to get the most represented ones for the text corpus. We found that 15 different topics would be most appropriate for the research papers. We also looked at how to interpret the topics from our text corpus. Our result, nonetheless, can be improved by using the Mallet model from gensim to perform our LDA analysis as it produces more accurate results."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('nlpiaenv': conda)",
   "language": "python",
   "name": "python361064bitnlpiaenvconda61f04f74d93d4de799586f1d9c3027f4"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
